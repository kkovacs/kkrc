[default]
# Make openrouter the default, to repeat less lines
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.request_timeout = 300
options.model = microsoft/mai-ds-r1:free

[l]
# Local Ollama with OpenAI compatibility:
options.token_load_fn = getenv('NO-NEED-FOR-TOKEN-FOR-LOCAL')
options.endpoint_url = http://127.0.0.1:11434/v1/chat/completions
# gemma3:latest is gemma3:4b, acceptably fast even on non-GPU notebooks with enough (16GB+) RAM:
options.model = gemma3:latest

##############
# OpenRouter
##############
# Check your spending at: https://openrouter.ai/activity

[q0]
options.model = qwen/qwen3-coder-30b-a3b-instruct

[q1]
options.model = qwen/qwen3-coder

[d0]
options.model = deepseek/deepseek-v3.2-exp

[d1]
options.model = deepseek/deepseek-r1-0528

[a0]
options.model = openai/gpt-5-mini

[a1]
options.model = openai/gpt-5

[g0]
options.model = google/gemini-2.5-flash

[g1]
options.model = google/gemini-2.5-pro-preview

[x0]
options.model = x-ai/grok-code-fast-1

[x1]
options.model = x-ai/grok-4

[c0]
options.model = anthropic/claude-3.5-haiku

[c1]
options.model = anthropic/claude-sonnet-4.5

###############################
# Google Gemini AI Studio API
###############################
# Check your spending at: https://aistudio.google.com/usage
# Get your API key at: https://aistudio.google.com/

[gg]
# Gemma is free, as of 2025-07-21
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
# XXX Workaround: If we pass a system prompt to gemma, we get "Developer instruction is not enabled"
options.initial_prompt =
options.model = gemma-3-27b-it

[gg0]
# USD 2.5
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
options.model = gemini-2.5-flash

[gg1]
# USD 10-15 (depends on context)
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
options.model = gemini-2.5-pro

#####################################
# Github Copilot OpenAI compatiblity
#####################################
# Get your API key like this: https://aider.chat/docs/llms/github.html
# Check "multipliers" at: https://docs.github.com/en/copilot/reference/ai-models/supported-models#model-multipliers
# Enable models and check your spending at: https://github.com/settings/copilot/features

[gh0]
# Free with paid plans
options.token_load_fn = getenv('OPENAI_API_KEY')
options.endpoint_url = https://api.githubcopilot.com/chat/completions
options.model = gpt-5-mini

[gh1]
options.token_load_fn = getenv('OPENAI_API_KEY')
options.endpoint_url = https://api.githubcopilot.com/chat/completions
options.model = gpt-5

######################
# Pre-defined prompts
######################

[ai]
prompt = Return the same code, but complete the task found in the comment that contains `AI!`.

[fix]
prompt = Return the same code, but fix errors, if any. Mark your changes with `FIXED:` and add a short explanation of the bug or fix.
