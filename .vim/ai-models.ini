[default]
# Configure a default model to your heart's content from below

# Prepare for larger contexts and thinking models
options.request_timeout = 60

[l]
# Local Ollama with OpenAI compatibility:
options.token_load_fn = "i-dont-need-a-token-for-ollama"
options.endpoint_url = http://127.0.0.1:11434/v1/chat/completions
# gemma3:latest is gemma3:4b, acceptably fast even on non-GPU notebooks with enough (16GB+) RAM:
options.model = gemma3:latest

###############################
# Google Gemini AI Studio API
###############################

# Check your spending at: https://aistudio.google.com/usage
# Get your API key at: https://aistudio.google.com/

[g]
# Gemma is free, as of 2025-07-21
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
# XXX Workaround: If we pass a system prompt to gemma, we get "Developer instruction is not enabled"
options.initial_prompt =
options.model = gemma-3-27b-it

[gfl]
# USD 0.4
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
options.model = gemini-2.5-flash-lite

[gf0]
# USD 0.4
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
options.model = gemini-2.0-flash

[gf]
# USD 2.5
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
options.model = gemini-2.5-flash

[gp]
# USD 10-15 (depends on context)
options.token_load_fn = getenv('GEMINI_API_KEY')
options.endpoint_url = https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
options.model = gemini-2.5-pro
# Thinking model
options.request_timeout = 300

###############################
# Cheap but good at OpenRouter
###############################

# Check your spending at: https://openrouter.ai/activity

[r]
# OpenRouter.AI
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
# Let's select a working free one by default, as of 2025-07-16
options.model = mistralai/devstral-small-2505:free
#options.model = deepseek/deepseek-chat:free

[devstral]
# USD 0.12
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = mistralai/devstral-small

[qwen]
# USD 0.3
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = qwen/qwen3-coder

[gemini-old]
# USD 0.4
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = google/gemini-2.0-flash-001

[gpt]
# USD 0.6
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = openai/gpt-4o-mini

[llama]
# USD 0.6
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = meta-llama/llama-4-maverick

[deepseek]
# USD 1
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = deepseek/deepseek-chat-v3.1

[grok]
# USD 1.5
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = x-ai/grok-code-fast-1

[devstral-big]
# USD 2.0
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = mistralai/devstral-medium

[gemini]
# USD 2.5
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = google/gemini-2.5-flash

##########################
# Mid-range at OpenRouter
##########################

[claude]
# USD 4
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = anthropic/claude-3.5-haiku

[o3]
# USD 4.4
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = openai/o3-mini-high

[o4]
# USD 4.4
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = openai/o4-mini-high

[gpt5]
# USD 5
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = openai/gpt-5

##########################
# Expensive at OpenRouter
##########################

[gemini-pro]
# USD 10-15 (depends on context size)
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = google/gemini-2.5-pro
# Thinking model
options.request_timeout = 300

[claude4]
# USD 15
options.token_load_fn = getenv('OPENROUTER_API_KEY')
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
options.model = anthropic/claude-sonnet-4

######################
# Pre-defined prompts
######################

[ai]
prompt = Return the same code, but complete the task found in the comment that contains `AI!`.

[fix]
prompt = Return the same code, but fix errors, if any. Mark your changes with `FIXED:` and add a short explanation of the bug or fix.
