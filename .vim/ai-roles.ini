[default]
# Default is local Ollama with OpenAI compatibility:
options.token_file_path = ~/.vim/ai-token.local
options.endpoint_url = http://127.0.0.1:11434/v1/chat/completions
options.model = gemma3:latest

[r]
# "r" for "router", as in, for OpenRouter.AI
# Check your spending at: https://openrouter.ai/activity
options.token_file_path = ~/.vim/ai-token
options.endpoint_url = https://openrouter.ai/api/v1/chat/completions
# Let's select a working free one by default, as of 2025-04-05
#options.model = google/gemini-2.5-pro-exp-03-25:free
#options.model = microsoft/phi-3-medium-128k-instruct:free
options.model = qwen/qwen2.5-vl-72b-instruct:free

######################
# Pre-defined prompts
######################

[todo]
prompt = Complete this code at the `// TODO` comment.

[fix]
prompt = Rewrite this code to fix any errors. Mark your changes with `// FIXED:` and a short explanation of the bug or fix.

###############################
# Cheap but good at OpenRouter
###############################

[qwen]
# $0.16
options.model = qwen/qwen-2.5-coder-32b-instruct

[msft]
# $0.16-$0.3
options.model = microsoft/phi-4

[gemma]
# $0.2
options.model = google/gemma-3-27b-it

[mistral]
# $0.25
options.model = mistralai/codestral-mamba

[llama]
# $0.3-$0.4
#options.model = meta-llama/llama-3.1-70b-instruct
# $0.3-$0.4
options.model = meta-llama/llama-3.3-70b-instruct

[gemini]
# $0.4
options.model = google/gemini-2.0-flash-001

[openai]
# $0.44
#options.model = openai/o3-mini
# $0.6
options.model = openai/gpt-4o-mini

##########################
# Mid-range at OpenRouter
##########################

[deepseek]
# $2.5-$5
options.model = deepseek/deepseek-r1

[claude]
# $4
options.model = anthropic/claude-3.5-haiku

[amazon]
# $3.2
options.model = amazon/nova-pro-v1

##########################
# Expensive at OpenRouter
##########################

[claude-big]
# $15
options.model = anthropic/claude-3.7-sonnet

[openai-big]
# $15
options.model = openai/chatgpt-4o-latest
